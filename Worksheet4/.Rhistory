install.packages("rmarkdown")
install.packages("devtools")
install.packages("tinytex")
install.packages("tinytex")
tinytex::install_tinytex()
install.packages("usethis")
require(ggplot2)
install.packages(ggplot2)
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
datampg <- glimpse(mpg)
str(mpg)
library(ggplot2)
data(mpg)
as.data.frame(data(mpg))
data(mpg)
mpg
str(mpg)
library(dplyr)
glimpse(mpg)
#1.
datampg <- glimpse(mpg)
ncol(mpg)
nrow(mpg)
install.packages("Hmisc")
install.packages("pastecs")
install.packages("pastecs")
install.packages("tidytext")
install.packages("plotly")
install.packages("wordcloud")
install.packages("RColorBrewer")
install.packages("dplyr")
install.packages("dplyr")
install.packages("wordcloud2")
install.packages("syuzhet")
install.packages("magrittr")
install.packages("stringr")
install.packages("twitteR")
install.packages("rtweet")
library(wordcloud)
library(wordcloud)
library(plotly)
library(tm)
library(dplyr)
library(RColorBrewer)
library(ggplot2)
library(twitteR)
library(rtweet)
# SETUP CREDENTIALS.
CONSUMER_KEY <- "eJDFmNbcF5J0tyWeHMVQXfSu3"
CONSUMER_SECRET <- "JJ7NU0919jp0PiPy2rUlUd9kNbHILLtMmhKjT4euDabesoiatl"
ACCESS_TOKEN <-  "1605820141249658880-6WuSKAKUe0g8QLUzVxBjLo3GZJBL4H"
ACCESS_SECRET <-  "03jmA42JLcDNScDg73vHedmk1Icxz7qiVg2X13PssMfnx"
setup_twitter_oauth(consumer_key = CONSUMER_KEY,
consumer_secret = CONSUMER_SECRET,
access_token = ACCESS_TOKEN,
access_secret = ACCESS_SECRET)
setup_twitter_oauth(consumer_key = CONSUMER_KEY,
consumer_secret = CONSUMER_SECRET,
access_token = ACCESS_TOKEN,
access_secret = ACCESS_SECRET)
data_tweets
# EXTRACTING TWEETS.
data_tweets <- searchTwitter("#Japan -filter:retweets", n=10000, lang="en",
since="2022-12-14", until="2022-12-21",
retryOnRateLimit = 120)
data_tweets
# CONVERTING LIST DATA TO DATA FRAME.
tweetsDF <- twListToDF(data_tweets)
class(tweetsDF)
names(tweetsDF)
View(tweetsDF)
head(tweetsDF)[1:5]
head(tweetsDF$text)[1:5]
# SAVE DATA FRAME FILE.
save(tweetsDF,file = "trendingTweetsDF.Rdata")
# CHECKING FOR MISSING VALUES IN A DATA FRAME.
data_chk <- sapply(tweetsDF, function(x) sum(is.na(x)))
data_chk
# SUBSETTING USING THE dplyr() PACKAGE.
tweetsDF2 <- tweetsDF %>%
select(screenName,text,created,statusSource)
tweetsDF2
# GROUPING THE DATA CREATED.
tweetsDF2 %>%
group_by(1) %>%
summarise(max = max(created), min = min(created))
# GROUPING THE DATA CREATED.
tweetsDF2 %>%
group_by(1) %>%
summarise(max = max(created), min = min(created))
# GROUPING THE DATA CREATED.
tweetsDF2 %>%
group_by(1) %>%
summarise(max = max(created), min = min(created))
#Adding column for Created at Round data
data_create <- tweetsDF %>%  mutate(Created_At_Round = created %>% round(units = 'hours') %>% as.POSIXct())
data_create
tweetsDF2 %>% pull(created) %>% min()
tweetsDF2 %>% pull(created) %>% max()
# Plot on tweets by time using the library(plotly) and ggplot().
plt_data <- data_create %>%
dplyr::count(Created_At_Round) %>%
ggplot(mapping = aes(x = Created_At_Round, y = n)) +
theme_light() +
geom_line() +
xlab(label = 'Date') +
ylab(label = NULL) +
ggtitle(label = 'Number of Tweets per Hour')
# Plot on tweets by time using the library(plotly) and ggplot().
plt_data <- data_create %>%
dplyr::count(Created_At_Round) %>%
ggplot(mapping = aes(x = Created_At_Round, y = n)) +
theme_light() +
geom_line() +
xlab(label = 'Date') +
ylab(label = NULL) +
ggtitle(label = 'Number of Tweets per Hour')
plt_data %>% ggplotly()
# ===
#pseodu plotting that has a legend
ggplot(data = tweetsDF, aes(x = created)) +
geom_histogram(aes(fill = ..count..)) +
theme(legend.position = "right") +
xlab("Time") + ylab("Number of tweets") +
scale_fill_gradient(low = "midnightblue", high = "aquamarine4")
# PLOTTING STATUS SOURCE.
encodeSource <- function(x) {
if(grepl(">Twitter for iPhone</a>", x)){
"iphone"
}else if(grepl(">Twitter for iPad</a>", x)){
"ipad"
}else if(grepl(">Twitter for Android</a>", x)){
"android"
} else if(grepl(">Twitter Web Client</a>", x)){
"Web"
} else if(grepl(">Twitter for Windows Phone</a>", x)){
"windows phone"
}else if(grepl(">dlvr.it</a>", x)){
"dlvr.it"
}else if(grepl(">IFTTT</a>", x)){
"ifttt"
}else if(grepl(">Facebook</a>", x)){  #This looks unreliable...
"facebook"
}else {
"others"
}
}
encodeSource <- function(x) {
if(grepl(">Twitter for iPhone</a>", x)){
"iphone"
}else if(grepl(">Twitter for iPad</a>", x)){
"ipad"
}else if(grepl(">Twitter for Android</a>", x)){
"android"
} else if(grepl(">Twitter Web Client</a>", x)){
"Web"
} else if(grepl(">Twitter for Windows Phone</a>", x)){
"windows phone"
}else if(grepl(">dlvr.it</a>", x)){
"dlvr.it"
}else if(grepl(">IFTTT</a>", x)){
"ifttt"
}else if(grepl(">Facebook</a>", x)){  #This looks unreliable...
"facebook"
}else {
"others"
}
}
#applying encodeSource funtion in the tweetsDF data
tweetsDF2$tweetSource = sapply(tweetsDF$statusSource,
encodeSource)
#Converting to dataframe
data_appSource <- tweetsDF2 %>%
select(tweetSource) %>%
group_by(tweetSource) %>%
summarize(count=n()) %>%
arrange(desc(count))
#Converting to dataframe
data_appSource <- tweetsDF2 %>%
select(tweetSource) %>%
group_by(tweetSource) %>%
summarize(count=n()) %>%
arrange(desc(count))
#Converting to dataframe
data_appSource <- tweetsDF2 %>%
select(tweetSource) %>%
group_by(tweetSource) %>%
summarize(count=n()) %>%
arrange(desc(count))
#Converting to dataframe
data_appSource <- tweetsDF2 %>%
select(tweetSource) %>%
group_by(tweetSource) %>%
summarize(count=n()) %>%
arrange(desc(count))
#Converting to dataframe
data_appSource <- tweetsDF2 %>%
select(tweetSource) %>%
group_by(tweetSource) %>%
summarize(count=n()) %>%
arrange(desc(count))
ggplot(tweetsDF2[tweetsDF2$tweetSource != 'others',], aes(tweetSource, fill = tweetSource)) +
geom_bar() +
theme(legend.position="none",
axis.title.x = element_blank(),
axis.text.x = element_text(angle = 45, hjust = 1)) +
ylab("Number of tweets") +
ggtitle("Tweets by Source")
data_appScreen <- tweetsDF2 %>%
select(screenName) %>%
group_by(screenName) %>%
summarize(count=n()) %>%
arrange(desc(count))
#convert to Corpus
namesCorpus_data <- Corpus(VectorSource(data_appScreen$screenName))  #using ScreenName
class(data_appScreen$screenName)
class(data_appScreen$screenName)
cls <- class(VectorSource(data_appScreen$screenName))
cls
str(namesCorpus_data)
class(namesCorpus_data)
nms <- namesCorpus_data
nms
# Wordcloud for the screenNames.
word_pal <- brewer.pal(8, "Dark2")
pal_word <- word_pal[-(1:4)]
set.seed(123)
par(mar = c(0,0,0,0), mfrow = c(1,1))
wordcloud(words = namesCorpus_data, scale=c(3,0.5),
max.words=10000,
random.order=FALSE,
rot.per=0.5,
use.r.layout=TRUE,
colors=pal_word)
wordcloud(words = namesCorpus_data, scale=c(3,0.5),
max.words=10000,
random.order=FALSE,
rot.per=0.5,
use.r.layout=TRUE,
colors=pal_word)
wordcloud(words = namesCorpus_data, scale=c(3,0.5),
max.words=10000,
random.order=FALSE,
rot.per=0.5,
use.r.layout=TRUE,
colors=pal_word)
wordcloud(words = namesCorpus_data, scale=c(3,0.5),
max.words=10000,
random.order=FALSE,
rot.per=0.5,
use.r.layout=TRUE,
colors=pal_word)
wordcloud(words = namesCorpus_data, scale=c(3,0.5),
max.words=10000,
random.order=FALSE,
rot.per=0.5,
use.r.layout=TRUE,
colors=pal_word)
wordcloud(words = namesCorpus_data, scale=c(3,0.5),
max.words=10000,
random.order=FALSE,
rot.per=0.5,
use.r.layout=TRUE,
colors=pal_word)
wordcloud(words = namesCorpus_data, scale=c(3,0.5),
max.words=10000,
random.order=FALSE,
rot.per=0.5,
use.r.layout=TRUE,
colors=pal_word)
wordcloud(words = namesCorpus_data, scale=c(3,0.5),
max.words=10000,
random.order=FALSE,
rot.per=0.5,
use.r.layout=TRUE,
colors=pal_word)
load("C:/Users/Jeremiah/OneDrive/Desktop/School/CS101/Project1/trendingTweetsDF.Rdata")
# SETUP CREDENTIALS.
CONSUMER_KEY <- "eJDFmNbcF5J0tyWeHMVQXfSu3"
CONSUMER_SECRET <- "JJ7NU0919jp0PiPy2rUlUd9kNbHILLtMmhKjT4euDabesoiatl"
ACCESS_TOKEN <-  "1605820141249658880-6WuSKAKUe0g8QLUzVxBjLo3GZJBL4H"
ACCESS_SECRET <-  "03jmA42JLcDNScDg73vHedmk1Icxz7qiVg2X13PssMfnx"
setup_twitter_oauth(consumer_key = CONSUMER_KEY,
consumer_secret = CONSUMER_SECRET,
access_token = ACCESS_TOKEN,
access_secret = ACCESS_SECRET)
# EXTRACTING TWEETS.
leaguetweets <- searchTwitter("#LeagueOfLegends", n=10000, lang="en", since="2022-11-25", until="2022-12-2", retryOnRateLimit = 120)
leaguetweets
leaguetweets
library(wordcloud)
library(plotly)
library(tm)
library(dplyr)
library(RColorBrewer)
library(ggplot2)
library(twitteR)
# SETUP CREDENTIALS.
CONSUMER_KEY <- "eJDFmNbcF5J0tyWeHMVQXfSu3"
CONSUMER_SECRET <- "JJ7NU0919jp0PiPy2rUlUd9kNbHILLtMmhKjT4euDabesoiatl"
ACCESS_TOKEN <-  "1605820141249658880-6WuSKAKUe0g8QLUzVxBjLo3GZJBL4H"
ACCESS_SECRET <-  "03jmA42JLcDNScDg73vHedmk1Icxz7qiVg2X13PssMfnx"
setup_twitter_oauth(consumer_key = CONSUMER_KEY,
consumer_secret = CONSUMER_SECRET,
access_token = ACCESS_TOKEN,
access_secret = ACCESS_SECRET)
# EXTRACTING TWEETS.
leaguetweets <- searchTwitter("#LeagueOfLegends", n=10000, lang="en", since="2022-11-25", until="2022-12-2", retryOnRateLimit = 120)
leaguetweets
# EXTRACTING TWEETS.
leaguetweets <- searchTwitter("#LeagueOfLegends", n=10000, lang="en", since="2022-11-17", until="2022-12-2", retryOnRateLimit = 120)
leaguetweets
leaguetweets <- searchTwitter("#LeagueOfLegends", n=10000, lang="en", since="2022-11-17", until="2022-12-2", retryOnRateLimit = 120)
leaguetweets
# EXTRACTING TWEETS.
leaguetweets <- searchTwitter("#LeagueOfLegends", n=10000, lang="en", since="2022-12-4", until="2022-12-11", retryOnRateLimit = 120)
# EXTRACTING TWEETS.
leaguetweets <- searchTwitter("#LeagueOfLegends", n=10000, lang="en", since="2022-12-04", until="2022-12-11", retryOnRateLimit = 120)
# EXTRACTING TWEETS.
leaguetweets <- searchTwitter("#LeagueOfLegends", n=10000, lang="en", since="2022-12-14", until="2022-12-21", retryOnRateLimit = 120)
leaguetweets <- searchTwitter("#LeagueOfLegends", n=10000, lang="en", since="2022-12-14", until="2022-12-21", retryOnRateLimit = 120)
leaguetweets
# CONVERTING LIST DATA TO DATA FRAME.
leaguetweetsDF <- twListToDF(leaguetweets)
# SAVE DATA FRAME FILE.
save(leaguetweetsDF,file = "leagueTweetsDF.Rdata")
sap_data <- sapply(leaguetweetsDF, function(x) sum(is.na(x)))
sap_data
# CHECKING FOR MISSING VALUES IN A DATA FRAME.
sap_data <- sapply(leaguetweetsDF, function(x) sum(is.na(x)))
sap_data
#Tweets
# SUBSETTING USING THE dplyr() PACKAGE.
tweets <- leaguetweetsDF %>%
select(screenName,text,created, isRetweet) %>% filter(isRetweet == FALSE)
#Tweets
# SUBSETTING USING THE dplyr() PACKAGE.
tweets <- leaguetweetsDF %>%
select(screenName,text,created, isRetweet) %>% filter(isRetweet == FALSE)
tweets
# GROUPING THE DATA CREATED.
tweets %>%
group_by(1) %>%
summarise(max = max(created), min = min(created))
# GROUPING THE DATA CREATED.
tweets %>%
group_by(1) %>%
summarise(max = max(created), min = min(created))
# GROUPING THE DATA CREATED.
tweets %>%
group_by(1) %>%
summarise(max = max(created), min = min(created))
crt_data <- tweets %>%  mutate(Created_At_Round = created %>% round(units = 'hours') %>% as.POSIXct())
crt_data
mn <- tweets %>% pull(created) %>% min()
mn
mx <- tweets %>% pull(created) %>% max()
mx
plt_data <- ggplot(crt_data, aes(x = Created_At_Round)) +
geom_histogram(aes(fill = ..count..)) +
theme(legend.position = "right") +
xlab("Time") + ylab("Number of tweets") +
scale_fill_gradient(low = "midnightblue", high = "aquamarine4")
plt_data %>% ggplotly()
sub_tweets <- leaguetweetsDF %>%
select(screenName,text,created, isRetweet) %>% filter(isRetweet == TRUE)
sub_tweets <- leaguetweetsDF %>%
select(screenName,text,created, isRetweet) %>% filter(isRetweet == TRUE)
sub_tweets
sub_tweets %>%
group_by(1) %>%
summarise(max = max(created), min = min(created))
sub_tweets %>%
group_by(1) %>%
summarise(max = max(created), min = min(created))
sub_tweets %>%
group_by(1) %>%
summarise(max = max(created), min = min(created))
crt2 <- sub_tweets %>%  mutate(Created_At_Round = created %>% round(units = 'hours') %>% as.POSIXct())
crt2
mn <- sub_tweets %>% pull(created) %>% min()
mn
mx <- sub_tweets %>% pull(created) %>% max()
mx
plt_data <- ggplot(crt2, aes(x = Created_At_Round)) +
geom_histogram(aes(fill = ..count..)) +
theme(legend.position = "right") +
xlab("Time") + ylab("Number of tweets") +
scale_fill_gradient(low = "midnightblue", high = "aquamarine4")
plt_data %>% ggplotly()
#Exporting the data abalone to the Microsoft excel file
install.packages("xlsxjars")
install.packages("AppliedPredictiveModeling")
a<- read.table("import_march.csv", header= TRUE, sep= "," )
a
a
getwd()
a <- read.table("import_march.csv", header= TRUE, sep= "," )
import
import
import <- read.table("import_march.csv", header = TRUE, sep=",")
getwd()
import <- read.table("import_march.csv", header = TRUE, sep=",")
e_data
import
setwd("C:/Users/Jeremiah/OneDrive/Desktop/School/CS101/Worksheet4")
getwd()
import <- read.table("import_march.csv", header = TRUE, sep=",")
#5a
setwd("C:/Users/Jeremiah/OneDrive/Desktop/School/CS101/Worksheet4")
getwd()
import <- read.table("import_march.csv", header = TRUE, sep=",")
shoesize <- c(6.5,9.0,8.5,8.5,10.5,7.0,9.5,9.0,13.0,
7.5,10.5,8.5,12.0,10.5,
13.0,11.5,8.5,5.0,10.0,
6.5,7.5,8.5,10.5,8.5,10.5,11.0,9.0,13.0)
height <- c(66.0,68.0,64.5,65.0,70.0,
64.0,70.0,71.0,72.0,64.0,
74.5,67.0,71.0,71.0,77.0,72.0,
59.0,62.0,72.0,66.0,64.0,67.0,73.0,
69.0,72.0,70.0,69.0,70)
gender <- c("F","F","F","F","M","F","M","F","M",
"M","M","F","M","M","M","M","F","F",
"M","F","M","M","M","F","M","M","M","M")
data_display <- data.frame(shoesize, height, gender)
data_display
